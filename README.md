# Подготовка к собеседованию для Spark Data Engineer
## Spark
### Структура Spark
### Spark Core
### Spark SQL 
### Spark Streaming
### Spark Catalist
### Отличия Spark и PySpark
* Основным отличием является обработка UDF, в том плане, что Python работает кратно медленнее, чем Scala
* Некоторые методы работают иначе, у некоторых разные параметры, но это надо точечно сравнить, общей инфы нет
### Ect
### Map-Reduce как аналог Spark
## Scala
### UDF
## Python
## Sql
### Joinы (включая spark)
### Оконки
### Greenplam
## Оркестраторы 
* Задачи решаемые оркестратором
  * Планирование задач — основная функция, позволяющая избавиться от ручного запуска рутинных задач по расчёту витрин, загрузке данных, резервному копированию
  * Управление зависимостями. Часто задачу нужно запустить не только в определённый промежуток времени, но и с учётом статуса других задач
  * Репроцессинг. Если известно, что какая-то задача требует перезапуска (например, были загружены неполные данные на предыдущем этапе), то перезапуска требуют и задачи, зависящие от неё. Кроме того, перезапуск может быть необходим за несколько временных периодов
  * Мониторинг
### Airflow
* В основе концепции Airflow лежит DAG — направленный ациклический граф. Он описывает процессы обработки данных и позволяет объединять задачи, определяя правила их совместной работы
  * https://airflow.apache.org/
* Airflow состоит из нескольких компонентов, но главные из них — scheduler и webserver. Без них ничего не запустится
  * Scheduler (планировщик) отслеживает все задачи и DAGs, а затем запускает экземпляры задач после установки их зависимостей. В фоновом режиме планировщик запускает подпроцесс, который отслеживает и синхронизирует все DAGs в указанном каталоге. По умолчанию он раз в минуту собирает результаты синтаксического анализа DAGs и проверяет, необходимо ли запустить какие-либо активные задачи
    * https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/scheduler.html
  * WebServer (веб-сервер) отвечает за отображение веб-интерфейса и аутентификацию пользователей, а также решает, к какой группе должен относиться тот или иной пользователь в соответствии с конфигурационным файлом
    * https://airflow.apache.org/docs/apache-airflow/stable/security/webserver.html
### Oozie
### Luigi
### NIFI
## Прочие полезности
### Hadoop
* Hadoop – это свободно распространяемый набор утилит, библиотек и фреймворк для разработки и выполнения распределённых программ, работающих на кластерах из сотен и тысяч узлов. Эта основополагающая технология хранения и обработки больших данных (Big Data) является проектом верхнего уровня фонда Apache Software Foundation.
  * Изначально писался на Java под MapReduce
* Список полезных команд (HDFS) https://docs.arenadata.io/ru/ADH/current/references/hdfs-cheatsheet.html
* Модули
  * HDFS - распределенная файловая система хадупа (Hadoop Distributed File System)
    * Являет собой технологию хранения данных на разных серверах (узлах/нодах)
    * Обеспечивает надежность за счет репликации (дублирования данных)
    * Архитектура
      * NameNode - основонй отдельный сервер для управления пространством имен файловой системы, хранящий дерево файлов, а также мета-данные файлов и каталогов
      * Secondary NameNode - дублирование NameNode для отказоустойчивости и быстрого восстановления. Находится на кластере в единственном экземпляре
      * DataNode - серверА с программным кодом отвечающим за файловые операции и работу с блоками данных
      * Client - пользователь/приложение взаимодействующие через API с HDFS
    * Особенности
      * Число репликаций по-умолчанию 3
      * Размер файла по-умолчанию 64 Мб
      * Спокойно хранит файлы размером больше 10 Gb
      * Не требует дорогого серверного оборудования
      * Репликация асинхронная и осуществляется на уровне кластера, а не на уровне узлов
      * Хорошая оптимизация для потоковых операций
      * Файловые операции выполняются асинхронно для разных файлов
      * Принцип WORM (Write-once and read-many, один раз записать – много раз прочитать) полностью освобождает систему от блокировок типа «запись-чтение». Запись в файл в одно время доступен только одному процессу, что исключает конфликты множественной записи
      * Хорошо настроенное сжатие данных -> экономия дискового пространства
      * Самодиагностика
      * Метаданные сервера имен хранятся в оперативной памяти -> быстрый доступ
    * Недостатки
      * При поломке NameNode кластер не работает, до восстановления
      * Нет репликации для Secondary NameNode
      * Нет возможности редактирования сохраненных файлов
      * Нет проверки целостности данных
      * Нет поддержки реляционных моделей данных
  * YARN - ресурсный менеджер Yet Another Resource Negotiator
    * Архитектура
      * ResourceManager (RM) — менеджер ресурсов, которых отвечает за распределение ресурсов, необходимых для работы распределенных приложений, и наблюдение за узлами кластера, где эти приложения выполняются. ResourceManager включает планировщик ресурсов (Scheduler) и диспетчер приложений (ApplicationsManager, AsM)
      * ApplicationMaster (AM) – мастер приложения, ответственный за планирование его жизненного цикла, координацию и отслеживание статуса выполнения, включая динамическое масштабирование потребления ресурсов, управление потоком выполнения, обработку ошибок и искажений вычислений, выполнение локальных оптимизаций
      * NodeManager (NM) – менеджер узла – агент, запущенный на узле кластера, который отвечает за отслеживание используемых вычислительных ресурсов (CPU, RAM и пр.), управление логами и отправку отчетов об использовании ресурсов планировщику. NodeManager управляет абстрактными контейнерами – ресурсами узла, доступными для конкретного приложения
      * Контейнер (Container) — набор физических ресурсов (ЦП, память, диск, сеть) в одном вычислительном узле кластера
    * Принципы работы YARN 
      * Клиентское приложение отправляет запрос в кластер
      * Менеджер ресурсов выделяет необходимые ресурсы для контейнера и запускает ApplicationMaster для обслуживания этого приложения
      * ApplicationMaster отправляет запрос менеджеру узла NodeManager, включая контекст запуска контейнера Container Launch Context (CLC)
      * ApplicationMaster выделяет контейнеры для приложения в каждом узле и контролирует их работу до завершения работы приложения
      * Для запуска контейнера менеджер узла копирует в локальное хранилище все необходимые зависимости (данные, исполняемые файлы, архивы)
      * По завершении задачи мастер приложения отменяет выделенный контейнер в диспетчере ресурсов, завершая жизненный цикл распределенного задания
      * Клиент может отслеживать состояние распределенного приложения, обращаясь к менеджеру ресурсов или сразу к мастеру приложения
  * Hadoop Common - набор инфраструктурных программных библиотек и утилит, которые используются в других решениях и родственных проектах, в частности, для управления распределенными файлами и создания необходимой инфраструктуры
  * Hadoop MapReduce - платформа программирования и выполнения распределённых MapReduce-вычислений, с использованием большого количества компьютеров (узлов, nodes), образующих кластер
### Casandra
### Kafka
### Flink
### ClickHouse
## Справочная информация
### Принципы и подходы разработки
### Dwh, DataLake, DataVault
### Форматы данных в BigData
* **Линейные** (строковые)
  * Строки данных хранятся вместе образуя непрерывное хранилище
  * Пониженная скорость чтения и выполнения изберательных запросов
  * Большой расход дискового пространства
  * Лучше подходят для потоковой записи
  * Виды
    * `AVRO`
      * Может использовать компактную бинарную кодировку или человекочитаемый формат JSON  
      * Обеспечивает высокую скорость записи
      * Подходит для Apache Kafka, Flume, DataLake
    * `Sequence`
      * Двоичный формат для хранения данных в виде сериализованных пар ключ/значение 
      * Обеспечивает хороший параллелизм при MapReduce  
* **Колоночные** (столбцовые)
  * Столбцы хранятся вместе, но могут обрабатываться отдельно друг от друга
  * Быстрое чтение данных в изберательных запросах
  * Занимает много оперативной памяти
  * Не подходит для потоковой записи, т.к. файл не может быть восстановлен из-за отсутствия точек синхронизации
  * Занимает меньше дискового пространства
  * Виды
    * `Parquet`
      * Бинарный, колоночно-ориентированный формат
      * Подходит для Kafka, Spark и Hadoop
      * Поддерживает boolean, int32, int64, int96, float, double, byte_array
      * *Достоинства*
        * Экономия места
        * Высокая скорость
        * Возможность реализации собственных схем данных
        * Многие ЯП поддерживают
        * Возможность хранения данных не только в HDFS
        * Простота и удобство работы с файлами
        * Поддержка Apache Spark «по умолчанию»
      * *Недостатки*
        * Строгая типизация данных
        * Отсутствие встроенной (нативной) поддержки в других фреймворках, кроме Apache Spark
        * Отсутствие возможности отслеживать изменение данных и эволюцию схемы
        * Сложность частичной потоковой передачи данных
        * Сильная привязка к метаданным
        * Паркет не является человекочитаемым форматом
    * `RCFile`
      * Гибридный многоколонный формат записей, адаптированный для хранения реляционных таблиц на кластерах и предназначенный для систем использующих MapReduce
    * `ORC`
      * *Достоинства*
        * Один файл на выходе любой задачи — это снижает нагрузку на узел имен (NameNode)
        * Поддерживается тип данных Hive, сложные и десятичные типы данных (list, map, struct, union)
        * Возможно одновременное считывание того же файла различными процессами RecordReader
        * Можно разделить файлы без сканирования этих файлов на предмет наличия маркеров
        * Индексация блоков для каждого столбца
        * Генерация наиболее эффективного графа при оптимизации SQL-запросов
### Алгоритмы
### Алгоритмы кластеризации
* Формально это больше про ML, но не помешает знать, что такое существует
* Кластеризация (или кластерный анализ) — это задача разбиения множества объектов на группы, называемые кластерами. Внутри каждой группы должны оказаться «похожие» объекты, а объекты разных группы должны быть как можно более отличны. Главное отличие кластеризации от классификации состоит в том, что перечень групп четко не задан и определяется в процессе работы алгоритма
* Виды:
  * `Иерархический`
  * `k-средних`
  * `с-средних`
  * `Выделение связных компонент`
  * `Минимально покрывающее дерево`
  * `Послойная кластеризация`
* Ссылка на статью - https://habr.com/ru/articles/101338/
## Остальное 
### Docker
### kubernets 
# Раскаиваться что первую итеррацию забыл сохранить =)
